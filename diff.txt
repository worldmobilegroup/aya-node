diff --git a/Cargo.lock b/Cargo.lock
index 9408dae..f500f90 100644
--- a/Cargo.lock
+++ b/Cargo.lock
@@ -717,8 +717,10 @@ dependencies = [
  "assert_matches",
  "async-trait",
  "aya-runtime",
+ "blake2 0.9.2",
  "clap",
  "env_logger 0.11.3",
+ "environmental",
  "fc-api",
  "fc-cli",
  "fc-consensus",
@@ -737,6 +739,7 @@ dependencies = [
  "frame-system-rpc-runtime-api",
  "futures 0.3.30",
  "futures-util",
+ "hex",
  "hex-literal",
  "hyper 1.3.1",
  "jsonrpc-core",
@@ -782,6 +785,7 @@ dependencies = [
  "sp-core",
  "sp-inherents",
  "sp-io",
+ "sp-keyring",
  "sp-offchain",
  "sp-runtime",
  "sp-session",
@@ -802,6 +806,7 @@ dependencies = [
 name = "aya-runtime"
 version = "0.1.0"
 dependencies = [
+ "environmental",
  "fp-account",
  "fp-evm",
  "fp-rpc",
@@ -1021,6 +1026,17 @@ dependencies = [
  "opaque-debug 0.2.3",
 ]
 
+[[package]]
+name = "blake2"
+version = "0.9.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "0a4e37d16930f5459780f5621038b6382b9bb37c19016f39fb6b5808d831f174"
+dependencies = [
+ "crypto-mac 0.8.0",
+ "digest 0.9.0",
+ "opaque-debug 0.3.1",
+]
+
 [[package]]
 name = "blake2"
 version = "0.10.6"
@@ -6001,10 +6017,12 @@ dependencies = [
 name = "pallet-epoch"
 version = "1.1.0"
 dependencies = [
+ "blake2 0.9.2",
  "fp-account",
  "frame-benchmarking",
  "frame-support",
  "frame-system",
+ "hex",
  "log",
  "mockall 0.12.1",
  "pallet-balances",
diff --git a/Cargo.toml b/Cargo.toml
index acb750a..976f65e 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -32,7 +32,7 @@ jsonrpsee-ws-server = { version = "0.15.1", default-features = false }
 jsonrpsee-http-client = { version = "0.22.5", default-features = false }
 
 
-
+blake2 = { version = "0.9.0", default-features = false }
 kvdb-rocksdb = { version = "0.19.0", default-features = false }
 libsecp256k1 = { version = "0.7.1", default-features = false }
 log = { version = "0.4.21", default-features = false }
@@ -63,6 +63,7 @@ lazy_static = "1.4.0"
 
 env_logger = "0.11.3"
 # Substrate Client
+
 sc-basic-authorship = { git = "https://github.com/paritytech/polkadot-sdk", branch = "release-polkadot-v1.9.0" }
 sc-block-builder = { git = "https://github.com/paritytech/polkadot-sdk", branch = "release-polkadot-v1.9.0" }
 sc-chain-spec = { git = "https://github.com/paritytech/polkadot-sdk", branch = "release-polkadot-v1.9.0" }
diff --git a/diff.txt b/diff.txt
index 0ea7930..e69de29 100644
--- a/diff.txt
+++ b/diff.txt
@@ -1,554 +0,0 @@
-diff --git a/pallets/pallet-epoch/src/lib.rs b/pallets/pallet-epoch/src/lib.rs
-index 1415cfd..62ae586 100644
---- a/pallets/pallet-epoch/src/lib.rs
-+++ b/pallets/pallet-epoch/src/lib.rs
-@@ -3,16 +3,16 @@ extern crate alloc;
- #[cfg_attr(feature = "std", macro_use)]
- extern crate serde;
- extern crate sp_std;
-+use alloc::format;
- use alloc::{string::ToString, vec::Vec};
- use core::primitive::str;
--use log::info;
--pub use pallet::*;
--
- use frame_support::{
-     dispatch::DispatchResult, pallet_prelude::*, storage::types::StorageMap,
-     unsigned::TransactionSource, weights::Weight,
- };
- use frame_system::{offchain::*, pallet_prelude::*};
-+use log::info;
-+pub use pallet::*;
- use serde::{Deserialize, Deserializer, Serialize, Serializer};
- 
- use sp_application_crypto::{AppCrypto, RuntimePublic};
-@@ -297,83 +297,6 @@ pub mod pallet {
-     }
- 
-     use alloc::format;
--    impl<T: Config> Pallet<T>
--    where
--        T: frame_system::offchain::SendTransactionTypes<Call<T>>,
--    {
--        fn create_inclusion_transaction() -> Result<(), &'static str> {
--            log::info!("Creating an inclusion transaction with an event payload");
--
--            // Create a unique nonce
--            let nonce: u64 = sp_io::offchain::timestamp().unix_millis();
--            let response = Self::fetch_all_events()?;
--
--            // Deserialize the events
--            let events: Vec<CustomEvent> = serde_json::from_slice(&response).map_err(|e| {
--                log::error!("Failed to deserialize events: {:?}", e);
--                <Error<T>>::JsonSerializationError
--            })?;
--
--            log::info!("Fetched events: {:?}", events);
--            // Fetch the latest event from the queue
--            let latest_event = {
--                // Fetch all events
--                // let events = Self::fetch_all_events().map_err(|e| {
--                //     log::error!("Error fetching events: {:?}", e);
--                //     "HttpFetchingError"
--                // })?;
--                // let events = Self::fetch_all_events();
--
--                // log::info!("Fetched events: {:?}", events);
--                // Check if there are any events to process
--                // if events.is_empty() {
--                //     log::info!("No events to process.");
--                //     return Err("No events in the queue");
--                // }
--
--                // Get the latest event
--                // events.last().ok_or("No events in the queue")?.clone()
--            };
--            // log::info!("Latest event before encoding: {:?}", latest_event.clone());
--
--            // Encode the latest event payload
--            // let payload_vec = latest_event.encode();
--            // Ensure the latest event is correctly encoded/decoded
--            // let encoded_event = serde_json::to_string(&latest_event).map_err(|e| {
--            //     log::error!("Error encoding event: {:?}", e);
--            //     "EncodingError"
--            // })?;
--            // log::info!("Encoded latest event: {}", encoded_event);
--            /////
--            // Simulate a larger payload with detailed event information
--            // let mut stub_event_data = Vec::new();
--            // for i in 0..100 {
--            //     stub_event_data.push(format!(
--            //         "{{\"event_id\":{},\"event_data\":\"data_{}\"}}",
--            //         i, i
--            //     ));
--            // }
--            // let payload_vec = stub_event_data.encode();
--            // log::info!("Encoded payload: {:?}", payload_vec);
--
--            // log::info!("Encoded payload: {:?}", stub_event_data);
--
--            // Create the call with the nonce and payload
--            // let call = Call::<T>::process_epoch_event {
--            //     nonce,
--            //     payload: encoded_event.clone().into(),
--            // };
--            // log::info!("Submitting call with payload: {:?}", encoded_event);
--
--            // // Submit the transaction
--            // match frame_system::offchain::SubmitTransaction::<T, Call<T>>::submit_unsigned_transaction(call.into()) {
--            //     Ok(_) => log::info!("Stub event transaction submitted successfully"),
--            //     Err(e) => log::error!("Error submitting stub event transaction: {:?}", e),
--            // }
--
--            Ok(())
--        }
--    }
- 
-     impl<T: Config> Pallet<T>
-     where
-@@ -398,181 +321,6 @@ pub mod pallet {
-         }
-     }
- 
--    impl<T: Config> Pallet<T> {
--        fn fetch_all_events() -> Result<Vec<u8>, Error<T>> {
--            // const HTTP_REMOTE_REQUEST: &str = "http://127.0.0.1:5555";
--            // const HTTP_HEADER_USER_AGENT: &str = "SubstrateOffchainWorker";
--            // const HTTP_HEADER_CONTENT_TYPE: &str = "Content-Type";
--            // const CONTENT_TYPE_JSON: &str = "application/json";
--            // const FETCH_TIMEOUT_PERIOD: u64 = 3000; // in milliseconds
--
--            // // Create the JSON-RPC request payload
--            // let json_payload = serde_json::json!({
--            //     "jsonrpc": "2.0",
--            //     "method": "list_all_events",
--            //     "params": [],
--            //     "id": 1
--            // })
--            // .to_string()
--            // .into_bytes();
--
--            // // Initiate an external HTTP POST request
--            // let request =
--            //     rt_offchain::http::Request::post(HTTP_REMOTE_REQUEST, vec![&json_payload])
--            //         .add_header("User-Agent", HTTP_HEADER_USER_AGENT)
--            //         .add_header(HTTP_HEADER_CONTENT_TYPE, CONTENT_TYPE_JSON)
--            //         .deadline(
--            //             sp_io::offchain::timestamp()
--            //                 .add(rt_offchain::Duration::from_millis(FETCH_TIMEOUT_PERIOD)),
--            //         )
--            //         .send()
--            //         .map_err(|_| <Error<T>>::HttpFetchingError)?;
--
--            // let response = request
--            //     .try_wait(
--            //         sp_io::offchain::timestamp()
--            //             .add(rt_offchain::Duration::from_millis(FETCH_TIMEOUT_PERIOD)),
--            //     )
--            //     .map_err(|_| <Error<T>>::HttpFetchingError)?
--            //     .map_err(|_| <Error<T>>::HttpFetchingError)?;
--
--            // if response.code != 200 {
--            //     log::error!("Non-200 response code: {}", response.code);
--            //     return Err(<Error<T>>::HttpFetchingError);
--            // }
--
--            // let response_body = response.body().collect::<Vec<u8>>();
--            // let json_string = String::from_utf8(response_body).map_err(|e| {
--            //     log::error!("Failed to parse response body as UTF-8: {:?}", e);
--            //     <Error<T>>::InvalidUtf8
--            // })?;
--
--            // log::info!("HTTP Response Body: {}", json_string); // Log the raw JSON response
--
--            // // First, parse the top-level JSON response
--            // let rpc_response: serde_json::Value = serde_json::from_str(&json_string).map_err(|e| {
--            //     log::error!("Failed to parse JSON-RPC response: {:?}", e);
--            //     <Error<T>>::InvalidResponseFormat
--            // })?;
--
--            // // Extract the "result" field which is a stringified JSON
--            // let result_str = rpc_response["result"].as_str().ok_or(<Error<T>>::InvalidResponseFormat)?;
--
--            // // Unescape the JSON string
--            // let unescaped_result_str = result_str.replace("\\\"", "\"").replace("\\\\", "\\");
--
--            // // Parse the unescaped JSON string to the actual result structure
--            // let inner_response: serde_json::Value = serde_json::from_str(&unescaped_result_str).map_err(|e| {
--            //     log::error!("Failed to parse inner JSON-RPC response: {:?}", e);
--            //     <Error<T>>::InvalidResponseFormat
--            // })?;
--
--            // // Extract the events array from the parsed inner response
--            // let events_value = inner_response["events"].as_array().ok_or(<Error<T>>::InvalidResponseFormat)?;
--
--            // // Convert the events to the expected structure
--            // let mut events: Vec<Vec<CustomEvent>> = Vec::new();
--            // for event_group in events_value.iter() {
--            //     let mut parsed_event_group = Vec::new();
--            //     for event_value in event_group.as_array().ok_or(<Error<T>>::InvalidResponseFormat)? {
--            //         let event_json_str = event_value["data"].as_str().ok_or(<Error<T>>::InvalidResponseFormat)?;
--            //         let nested_data: serde_json::Value = serde_json::from_str(event_json_str).map_err(|e| {
--            //             log::error!("Failed to parse nested data field: {:?}", e);
--            //             <Error<T>>::JsonSerializationError
--            //         })?;
--
--            //         // Reconstruct the CustomEvent
--            //         let event = CustomEvent {
--            //             id: event_value["id"].as_u64().unwrap_or_default(),
--            //             data: CustomData(BoundedVec::try_from(nested_data.to_string().into_bytes()).map_err(|_| <Error<T>>::JsonSerializationError)?),
--            //             timestamp: event_value["timestamp"].as_u64().unwrap_or_default(),
--            //             block_height: event_value["block_height"].as_u64().unwrap_or_default(),
--            //             last_epoch: nested_data["last_epoch"].as_u64().unwrap_or_default(),
--            //             last_blockhash: BoundedVec::try_from(nested_data["last_blockhash"].as_str().unwrap_or_default().as_bytes().to_vec()).map_err(|_| <Error<T>>::JsonSerializationError)?,
--            //             last_slot: nested_data["last_slot"].as_u64().unwrap_or_default(),
--            //             new_epoch: nested_data["new_epoch"].as_u64().unwrap_or_default(),
--            //             new_slot: nested_data["new_slot"].as_u64().unwrap_or_default(),
--            //             new_blockhash: BoundedVec::try_from(nested_data["new_blockhash"].as_str().unwrap_or_default().as_bytes().to_vec()).map_err(|_| <Error<T>>::JsonSerializationError)?,
--            //             epoch_nonce: BoundedVec::try_from(nested_data["epoch_nonce"].as_str().unwrap_or_default().as_bytes().to_vec()).map_err(|_| <Error<T>>::JsonSerializationError)?,
--            //             extra_entropy: nested_data["extra_entropy"].as_str().map(|s| BoundedVec::try_from(s.as_bytes().to_vec()).map_err(|_| <Error<T>>::JsonSerializationError)).transpose()?,
--            //         };
--
--            //         parsed_event_group.push(event);
--            //     }
--            //     events.push(parsed_event_group);
--            // }
--
--            // if events.is_empty() {
--            //     log::info!("No events to process.");
--            //     return Err(<Error<T>>::NoEventsInQueue);
--            // }
--
--            // let events_json = serde_json::to_string(&events).map_err(|e| {
--            //     log::error!("Failed to serialize events: {:?}", e);
--            //     <Error<T>>::JsonSerializationError
--            // })?;
--
--            // Ok(events_json.into_bytes())
--            fn create_empty_json() -> Vec<u8> {
--                let empty_json = serde_json::json!({
--                    "events": [[{
--                        "id": 1,
--                        "data": [],
--                        "timestamp": 0,
--                        "block_height": 0,
--                        "last_epoch": 0,
--                        "last_blockhash": [],
--                        "last_slot": 0,
--                        "new_epoch": 0,
--                        "new_slot": 0,
--                        "new_blockhash": [],
--                        "epoch_nonce": [],
--                        "extra_entropy": null
--                    }]], // Note the nested array to match Vec<Vec<CustomEvent>>
--                    "success": true
--                });
--                serde_json::to_vec(&empty_json).unwrap_or_default()
--            }
--            fn create_json_with_event() -> Vec<u8> {
--                let event_json = serde_json::json!({
--                    "events": [{
--                        "id": 1,
--                        "data": {
--                            "type": "EpochChange",
--                            "data": {
--                                "last_epoch": 574,
--                                "last_blockhash": "de3ea4083d96987a9a3d2f1df14a009fdb548f7063a40fb707d2b87ca471cc5d",
--                                "last_slot": 49679976,
--                                "new_epoch": 575,
--                                "new_slot": 49680007,
--                                "new_blockhash": "18f9fe3cce213d40f8f16e16e73dad7dd28cf394d7e25c720cc83324ca8fa560",
--                                "epoch_nonce": "8972981c2fa11e815ab0b89e7c1e1603fe30b2c4d4eb6becaf109bf2fd912a22",
--                                "extra_entropy": null
--                            }
--                        },
--                        "timestamp": 1620000000,
--                        "block_height": 100,
--                        "last_epoch": 574,
--                        "last_blockhash": "de3ea4083d96987a9a3d2f1df14a009fdb548f7063a40fb707d2b87ca471cc5d",
--                        "last_slot": 49679976,
--                        "new_epoch": 575,
--                        "new_slot": 49680007,
--                        "new_blockhash": "18f9fe3cce213d40f8f16e16e73dad7dd28cf394d7e25c720cc83324ca8fa560",
--                        "epoch_nonce": "8972981c2fa11e815ab0b89e7c1e1603fe30b2c4d4eb6becaf109bf2fd912a22",
--                        "extra_entropy": null
--                    }],
--                    "success": true
--                });
--
--                serde_json::to_vec(&event_json).unwrap_or_default()
--            }
--
--            // let empty_json = create_empty_json();
--            let empty_json = Self::process_real_event()?;
--            Ok(empty_json)
--        }
--    }
--
-     impl<T: Config> Pallet<T>
-     where
-         <T as pallet::Config>::ValidatorId:
-@@ -665,58 +413,68 @@ pub mod pallet {
- 
-             // Process each event
-             let mut processed_events = Vec::new();
--    for (i, event_group) in events.iter().enumerate() {
--        let mut processed_group = Vec::new();
--        for (j, event) in event_group.as_array().ok_or_else(|| {
--            log::error!("Event group {} is not an array", i);
--            <Error<T>>::InvalidResponseFormat
--        })?.iter().enumerate() {
--            log::info!("Processing event {}.{}: {:?}", i, j, event);
--
--            // Check if the event is a JSON object
--            if let Some(event_obj) = event.as_object() {
--                let id = event_obj["id"].as_u64().ok_or_else(|| {
--                    log::error!("Failed to extract id from event {}.{}", i, j);
--                    <Error<T>>::InvalidResponseFormat
--                })?;
--                let timestamp = event_obj["timestamp"].as_u64().ok_or_else(|| {
--                    log::error!("Failed to extract timestamp from event {}.{}", i, j);
--                    <Error<T>>::InvalidResponseFormat
--                })?;
--                let block_height = event_obj["block_height"].as_u64().ok_or_else(|| {
--                    log::error!("Failed to extract block_height from event {}.{}", i, j);
--                    <Error<T>>::InvalidResponseFormat
--                })?;
--                
--                // Parse the data field, which is a stringified JSON
--                let data_str = event_obj["data"].as_str().ok_or_else(|| {
--                    log::error!("Failed to extract data string from event {}.{}", i, j);
--                    <Error<T>>::InvalidResponseFormat
--                })?;
--
--                log::info!("Data string for event {}.{}: {}", i, j, data_str);
--
--                let data: CustomData = serde_json::from_str(data_str).map_err(|e| {
--                    log::error!("Failed to parse event data for event {}.{}: {:?}", i, j, e);
--                    <Error<T>>::JsonSerializationError
--                })?;
--
--                let custom_event = CustomEvent {
--                    id,
--                    data,
--                    timestamp,
--                    block_height,
--                };
--
--                log::info!("Processed event {}.{}: {:?}", i, j, custom_event);
--
--                processed_group.push(custom_event);
--            } else {
--                log::warn!("Skipping non-object event {}.{}: {:?}", i, j, event);
-+            for (i, event_group) in events.iter().enumerate() {
-+                let mut processed_group = Vec::new();
-+                for (j, event) in event_group
-+                    .as_array()
-+                    .ok_or_else(|| {
-+                        log::error!("Event group {} is not an array", i);
-+                        <Error<T>>::InvalidResponseFormat
-+                    })?
-+                    .iter()
-+                    .enumerate()
-+                {
-+                    log::info!("Processing event {}.{}: {:?}", i, j, event);
-+
-+                    // Check if the event is a JSON object
-+                    if let Some(event_obj) = event.as_object() {
-+                        let id = event_obj["id"].as_u64().ok_or_else(|| {
-+                            log::error!("Failed to extract id from event {}.{}", i, j);
-+                            <Error<T>>::InvalidResponseFormat
-+                        })?;
-+                        let timestamp = event_obj["timestamp"].as_u64().ok_or_else(|| {
-+                            log::error!("Failed to extract timestamp from event {}.{}", i, j);
-+                            <Error<T>>::InvalidResponseFormat
-+                        })?;
-+                        let block_height = event_obj["block_height"].as_u64().ok_or_else(|| {
-+                            log::error!("Failed to extract block_height from event {}.{}", i, j);
-+                            <Error<T>>::InvalidResponseFormat
-+                        })?;
-+
-+                        // Parse the data field, which is a stringified JSON
-+                        let data_str = event_obj["data"].as_str().ok_or_else(|| {
-+                            log::error!("Failed to extract data string from event {}.{}", i, j);
-+                            <Error<T>>::InvalidResponseFormat
-+                        })?;
-+
-+                        log::info!("Data string for event {}.{}: {}", i, j, data_str);
-+
-+                        let data: CustomData = serde_json::from_str(data_str).map_err(|e| {
-+                            log::error!(
-+                                "Failed to parse event data for event {}.{}: {:?}",
-+                                i,
-+                                j,
-+                                e
-+                            );
-+                            <Error<T>>::JsonSerializationError
-+                        })?;
-+
-+                        let custom_event = CustomEvent {
-+                            id,
-+                            data,
-+                            timestamp,
-+                            block_height,
-+                        };
-+
-+                        log::info!("Processed event {}.{}: {:?}", i, j, custom_event);
-+
-+                        processed_group.push(custom_event);
-+                    } else {
-+                        log::warn!("Skipping non-object event {}.{}: {:?}", i, j, event);
-+                    }
-+                }
-+                processed_events.push(processed_group);
-             }
--        }
--        processed_events.push(processed_group);
--    }
- 
-             // Serialize the processed events back to JSON
-             let events_json = serde_json::to_string(&processed_events).map_err(|e| {
-@@ -827,86 +585,6 @@ pub mod pallet {
-             Ok(())
-         }
- 
--        // fn fetch_and_process_events_from_queue() -> Result<(), Error<T>> {
--        //     log::info!("Fetching all events from the queue");
--
--        //     // Fetch all events
--        //     let response = Self::fetch_all_events()?;
--        //     let bounded_body: BoundedVec<u8, MaxDataLength> = BoundedVec::try_from(response).map_err(|_| {
--        //         log::error!("Failed to convert to BoundedVec");
--        //         <Error<T>>::HttpFetchingError
--        //     })?;
--
--        //     // Deserialize the events
--        //     let events: Vec<CustomEvent> = serde_json::from_slice(&bounded_body).map_err(|e| {
--        //         log::error!("Failed to deserialize events: {:?}", e);
--        //         <Error<T>>::JsonSerializationError
--        //     })?;
--
--        //     // Process all events if node is the leader
--        //     if Self::is_leader() {
--        //         log::info!("Node is the leader, processing events");
--
--        //         let mut events_to_remove: BoundedVec<u64, MaxRemoveEventsLength> =
--        //             BoundedVec::default();
--
--        //         for event in bounded_events.iter() {
--        //             log::info!("Validating and processing event: {:?}", event);
--
--        //             // Validate and process the event
--        //             Self::validate_and_process_event(event.clone())?;
--
--        //             // Encode the event payload
--        //             let payload = event.encode();
--
--        //             // Submit the encoded payload as an unsigned transaction
--        //             log::info!(
--        //                 "Submitting unsigned transaction with payload: {:?}",
--        //                 payload
--        //             );
--
--        //             // Decode the payload to create a call
--        //             let call = match Call::<T>::decode(&mut &payload[..]) {
--        //                 Ok(call) => call,
--        //                 Err(_) => {
--        //                     log::error!("Failed to decode the provided transaction payload");
--        //                     continue;
--        //                 }
--        //             };
--
--        //             // Submit the transaction
--        //             match frame_system::offchain::SubmitTransaction::<T, Call<T>>::submit_unsigned_transaction(
--        //                 call.into(),
--        //             ) {
--        //                 Ok(_) => {
--        //                     // If submission is successful, mark event for removal
--        //                     log::info!(
--        //                         "Transaction submitted successfully, marking event for removal: {:?}",
--        //                         event.id
--        //                     );
--        //                     events_to_remove
--        //                         .try_push(event.id)
--        //                         .map_err(|_| <Error<T>>::StorageOverflow)?;
--        //                 },
--        //                 Err(e) => {
--        //                     log::error!("Error submitting unsigned transaction: {:?}", e);
--        //                 }
--        //             }
--        //         }
--
--        //         // Remove processed events from the storage
--        //         for event_id in events_to_remove {
--        //             log::info!(
--        //                 "Removing processed event from priority queue: {:?}",
--        //                 event_id
--        //             );
--        //             Self::remove_event_from_priority_queue(event_id)?;
--        //         }
--        //     }
--
--        //     Ok(())
--        // }
--
-         fn remove_event_from_priority_queue(event_id: u64) -> Result<(), Error<T>> {
-             // Call the HTTP method to remove the event from the priority queue
-             let remove_event_payload = serde_json::json!({
-@@ -963,6 +641,31 @@ pub mod pallet {
-         fn get_event(event_id: u64) -> Option<CustomEvent> {
-             Some(EventStorage::<T>::get(event_id))
-         }
-+        // Use structured logging for better clarity in logs.
-+        fn log_event_processing(event: &CustomEvent) {
-+            log::info!(
-+                target: "event_processing",
-+                "Processing event: id={}, timestamp={}, block_height={}",
-+                event.id, event.timestamp, event.block_height
-+            );
-+        }
-+
-+        
-+    }
-+    
-+
-+    // Add more descriptive error messages to help with debugging.
-+    impl<T: Config> Pallet<T> {
-+        fn error_description(error: &Error<T>) -> &'static str {
-+            match error {
-+                Error::HttpFetchingError => "HTTP request failed",
-+                Error::InvalidUtf8 => "UTF-8 conversion error",
-+                Error::InvalidResponseFormat => "Response format is incorrect",
-+                Error::JsonSerializationError => "Error serializing or deserializing JSON",
-+                Error::InvalidEventData => "Event data validation failed",
-+                _ => "Unknown error",
-+            }
-+        }
-     }
- 
-     #[derive(Deserialize, Debug)]
-@@ -1001,6 +704,9 @@ pub mod pallet {
-         }
-     }
- 
-+    
-+
-+
-     #[pallet::call]
-     impl<T: Config> Pallet<T> {
-         #[pallet::call_index(0)]
-diff --git a/pallets/substrate-validator-set/src/mock.rs b/pallets/substrate-validator-set/src/mock.rs
-index 3c1893e..8fc2282 100644
---- a/pallets/substrate-validator-set/src/mock.rs
-+++ b/pallets/substrate-validator-set/src/mock.rs
-@@ -81,8 +81,8 @@ pub struct TestShouldEndSession;
- impl ShouldEndSession<u64> for TestShouldEndSession {
- 	fn should_end_session(now: u64) -> bool {
- 		let l = SessionLength::get();
--		now % l == 0 ||
--			ForceSessionEnd::mutate(|l| {
-+		now % l == 0
-+			|| ForceSessionEnd::mutate(|l| {
- 				let r = *l;
- 				*l = false;
- 				r
diff --git a/node/Cargo.toml b/node/Cargo.toml
index 7b3aa62..eab86c0 100644
--- a/node/Cargo.toml
+++ b/node/Cargo.toml
@@ -28,9 +28,9 @@ jsonrpc-derive = "18.0.0"
 serde = { version = "1.0", features = ["derive"] }
 sp-io = { workspace = true }
 jsonrpc-core-client = "18.0.0" 
-
-
-
+hex = { workspace = true }
+blake2 = { workspace = true }
+environmental = { workspace = true }
 # Substrate
 prometheus-endpoint = { workspace = true }
 sc-basic-authorship = { workspace = true }
@@ -89,8 +89,8 @@ fp-dynamic-fee = { workspace = true, features = ["default"] }
 fp-evm = { workspace = true, features = ["default"] }
 fp-rpc = { workspace = true, features = ["default"] }
 aya-runtime = { workspace = true, features = ["std"] }
-
-
+# substrate-api-client = { workspace = true }
+sp-keyring = { workspace = true }
 
 jsonrpsee-ws-server = { workspace = true }
 
diff --git a/node/src/rpc/priority_queue_rpc.rs b/node/src/rpc/priority_queue_rpc.rs
index bf411d9..4fb6ab1 100644
--- a/node/src/rpc/priority_queue_rpc.rs
+++ b/node/src/rpc/priority_queue_rpc.rs
@@ -4,251 +4,140 @@ use jsonrpsee_types::ErrorObjectOwned;
 use priority_queue::PriorityQueue;
 use serde::{Deserialize, Serialize};
 use serde_json::json;
+use std::collections::hash_map::DefaultHasher;
 use std::collections::HashSet;
+use std::hash::{Hash, Hasher};
 use std::net::SocketAddr;
 use std::sync::Arc;
 use tokio::sync::Mutex;
-use tracing::{error, info};
+use tracing::info;
 
 #[derive(Serialize, Deserialize, Debug, Eq, Hash, PartialEq, PartialOrd, Ord, Clone)]
 struct Event {
-    id: u64, // Add an ID field to the Event struct
+    id: u64,
     data: String,
     timestamp: u64,
     block_height: u64,
 }
 
-#[derive(Serialize, Deserialize)]
-struct UpdatePriorityParams {
-    id: u64,
-    new_priority: i32,
-}
-
-pub async fn run_server() -> anyhow::Result<SocketAddr> {
-    let pq = Arc::new(Mutex::new(PriorityQueue::<Event, i32>::new()));
-    let event_ids = Arc::new(Mutex::new(HashSet::<u64>::new()));
-    let context = Arc::new((pq, event_ids));
+impl Event {
+    
 
-    let server = Server::builder().build("127.0.0.1:5555").await?;
-    let addr = server.local_addr()?;
-    info!("RPC server running on {}", addr);
+    pub fn is_valid(&self) -> bool {
+        self.timestamp != 0 && self.block_height != 0
+    }
 
-    let mut module = RpcModule::new(context);
+    pub fn hash_without_timestamp(&self) -> u64 {
+        let mut hasher = DefaultHasher::new();
+        self.id.hash(&mut hasher);
+        self.data.hash(&mut hasher);
+        self.block_height.hash(&mut hasher);
+        hasher.finish()
+    }
+}
 
-    module.register_async_method("submit_event", |params, ctx| async move {
-        let (pq, event_ids) = &**ctx;
-        let (event, priority) = params.parse::<(Event, i32)>()?;
+struct EventQueue {
+    queue: PriorityQueue<Event, i32>,
+    event_hashes: HashSet<u64>,
+    processed_events: HashSet<u64>,
+}
 
-        let mut event_ids = event_ids.lock().await;
-        if event_ids.contains(&event.id) {
-            error!("Event with id {} already exists", event.id);
-            return Ok::<_, ErrorObjectOwned>("Event with the same id already exists".to_string());
+impl EventQueue {
+    fn new() -> Self {
+        EventQueue {
+            queue: PriorityQueue::new(),
+            event_hashes: HashSet::new(),
+            processed_events: HashSet::new(),
         }
+    }
 
-        let mut pq = pq.lock().await;
-        event_ids.insert(event.id);
-        println!("Received event: {:?} with priority: {}", event, priority);
-        pq.push(event, priority);
-        Ok::<_, ErrorObjectOwned>("Event submitted successfully".to_string())
-    })?;
-
-    module.register_async_method("list_all_events", |_, ctx| async move {
-        let (pq, _) = &**ctx;
-        let mut pq = pq.lock().await;
-        let events = pq.iter().map(|(e, p)| (e.clone(), *p)).collect::<Vec<_>>();
-        if !events.is_empty() {
-            tracing::info!("response: {:?}", "Events listed successfully");
-            Ok::<_, ErrorObjectOwned>(
-                serde_json::to_string(&json!({
-                    "success": true,
-                    "events": events
-                }))
-                .unwrap(),
-            )
-        } else {
-            Ok(serde_json::to_string(&json!({
-                "success": false,
-                "message": "No events found"
-            }))
-            .unwrap())
-        }
-    })?;
+    fn is_duplicate(&self, event: &Event) -> bool {
+        self.event_hashes.contains(&event.hash_without_timestamp())
+    }
 
-    module.register_async_method("clear_all_events", |_, ctx| async move {
-        let (pq, event_ids) = &**ctx;
-        let mut pq = pq.lock().await;
-        let mut event_ids = event_ids.lock().await;
-        pq.clear();
-        event_ids.clear();
-        tracing::info!("response: {:?}", "Events cleared successfully");
-        Ok::<_, ErrorObjectOwned>("All events cleared".to_string())
-    })?;
+    fn mark_as_processed(&mut self, event_id: u64) {
+        self.processed_events.insert(event_id);
+    }
 
-    module.register_async_method("pop", |_, ctx| async move {
-        let (pq, event_ids) = &**ctx;
-        let mut pq = pq.lock().await;
-        let mut event_ids = event_ids.lock().await;
-        if let Some((event, _priority)) = pq.pop() {
-            event_ids.remove(&event.id);
-            tracing::info!("response: {:?}", "Event popped successfully");
-            Ok::<_, ErrorObjectOwned>(
-                serde_json::to_string(&json!({
-                    "success": true,
-                    "event": event
-                }))
-                .unwrap(),
-            )
-        } else {
-            Ok(serde_json::to_string(&json!({
-                "success": false,
-                "message": "No events to pop"
-            }))
-            .unwrap())
+    fn push(&mut self, event: Event, priority: i32) -> Result<(), String> {
+        if self.is_duplicate(&event) {
+            return Err(format!("Duplicate event: {:?}", event));
         }
-    })?;
+        self.queue.push(event.clone(), priority);
+        self.event_hashes.insert(event.hash_without_timestamp());
+        Ok(())
+    }
+
+    fn iter(&self) -> impl Iterator<Item = (&Event, &i32)> {
+        self.queue.iter()
+    }
+}
 
-    module.register_async_method("get_event_count", |_, ctx| async move {
-        let (pq, _) = &**ctx;
-        let pq = pq.lock().await;
-        let response = json!({
-            "jsonrpc": "2.0",
-            "result": pq.len(),
-            "id": 1
-        })
-        .to_string();
-        Ok::<_, ErrorObjectOwned>(response)
-    })?;
+pub async fn run_server() -> anyhow::Result<SocketAddr> {
+    let server = Server::builder().build("127.0.0.1:5555").await?;
+    let addr = server.local_addr()?;
+    info!("RPC server running on {}", addr);
 
-    module.register_async_method("get_event_by_id", |params, ctx| async move {
-        let (pq, _) = &**ctx;
-        let id: u64 = params.one()?;
-        let pq = pq.lock().await;
-        let event = pq.iter().find(|(e, _)| e.id == id).map(|(e, _)| e.clone());
-        if let Some(event) = event {
-            Ok::<_, ErrorObjectOwned>(
-                serde_json::to_string(&json!({
-                    "success": true,
-                    "event": event
-                }))
-                .unwrap(),
-            )
-        } else {
-            Ok::<_, ErrorObjectOwned>(
-                serde_json::to_string(&json!({
-                    "success": false,
-                    "message": "Event not found"
-                }))
-                .unwrap(),
-            )
-        }
-    })?;
+    let event_queue = Arc::new(Mutex::new(EventQueue::new()));
+    let mut module = RpcModule::new(event_queue.clone());
 
-    module.register_async_method("update_event_priority", |params, ctx| async move {
-        let (pq, _) = &**ctx;
-        let UpdatePriorityParams { id, new_priority } = params.parse()?;
-        let mut pq = pq.lock().await;
-        let mut event_opt = None;
+    module.register_async_method("list_all_events", |_, event_queue| async move {
+        let mut queue = event_queue.lock().await;
         let mut events = Vec::new();
-        while let Some((e, p)) = pq.pop() {
-            if e.id == id {
-                event_opt = Some((e, new_priority));
+        let mut duplicates = Vec::new();
+        let mut to_mark_processed = Vec::new();
+
+        // Collect all events and identify duplicates
+        for (event, priority) in queue.iter() {
+            if queue.processed_events.contains(&event.id) {
+                duplicates.push((event.clone(), *priority));
             } else {
-                events.push((e, p));
+                events.push((event.clone(), *priority));
+                to_mark_processed.push(event.id);
             }
         }
-        for (e, p) in events {
-            pq.push(e, p);
-        }
-        if let Some((event, priority)) = event_opt {
-            pq.push(event, priority);
-            Ok::<_, ErrorObjectOwned>("Event priority updated successfully".to_string())
-        } else {
-            Ok::<_, ErrorObjectOwned>("Event not found".to_string())
-        }
-    })?;
 
-    module.register_async_method("get_events_by_timestamp", |params, ctx| async move {
-        let (pq, _) = &**ctx;
-        let (start, end): (u64, u64) = params.parse()?;
-        let pq = pq.lock().await;
-        let events = pq
-            .iter()
-            .filter(|(e, _)| e.timestamp >= start && e.timestamp <= end)
-            .map(|(e, p)| (e.clone(), *p))
-            .collect::<Vec<_>>();
-        if !events.is_empty() {
-            Ok::<_, ErrorObjectOwned>(
-                serde_json::to_string(&json!({
-                    "success": true,
-                    "events": events
-                }))
-                .unwrap(),
-            )
-        } else {
-            Ok::<_, ErrorObjectOwned>(
-                serde_json::to_string(&json!({
-                    "success": false,
-                    "message": "No events found in the given timestamp range"
-                }))
-                .unwrap(),
-            )
+        // Mark new events as processed
+        for event_id in to_mark_processed {
+            queue.mark_as_processed(event_id);
         }
-    })?;
 
-    module.register_async_method("request_event", |params, ctx| async move {
-        let (pq, _) = &**ctx;
-        let event_id: u64 = params.one()?;
-        let pq = pq.lock().await;
-        let event = pq
-            .iter()
-            .find(|(e, _)| e.id == event_id)
-            .map(|(e, _)| e.clone());
-        if let Some(event) = event {
+        if !events.is_empty() || !duplicates.is_empty() {
+            tracing::info!(
+                "Events listed successfully. New events: {}, Duplicates: {}",
+                events.len(),
+                duplicates.len()
+            );
             Ok::<_, ErrorObjectOwned>(
                 serde_json::to_string(&json!({
                     "success": true,
-                    "event": event
+                    "events": events,
+                    "duplicates": duplicates
                 }))
                 .unwrap(),
             )
         } else {
-            Ok::<_, ErrorObjectOwned>(
-                serde_json::to_string(&json!({
-                    "success": false,
-                    "message": "Event not found"
-                }))
-                .unwrap(),
-            )
+            Ok(serde_json::to_string(&json!({
+                "success": false,
+                "message": "No events found"
+            }))
+            .unwrap())
         }
     })?;
 
-    module.register_async_method("remove_event", |params, ctx| async move {
-        let (pq, event_ids) = &**ctx;
-        let event_id: u64 = params.one()?;
-        let mut pq = pq.lock().await;
-        let mut event_ids = event_ids.lock().await;
-        let mut found = false;
+    module.register_async_method("submit_event", |params, event_queue| async move {
+        let (event, priority) = params.parse::<(Event, i32)>()?;
+        let mut queue = event_queue.lock().await;
 
-        let mut temp_queue = PriorityQueue::new();
-        while let Some((event, priority)) = pq.pop() {
-            if event.id == event_id {
-                found = true;
-                break;
-            } else {
-                temp_queue.push(event, priority);
+        match queue.push(event.clone(), priority) {
+            Ok(_) => {
+                tracing::info!("Received event: {:?} with priority: {}", event, priority);
+                Ok::<_, ErrorObjectOwned>("Event submitted successfully".to_string())
+            }
+            Err(e) => {
+                tracing::error!("Failed to submit event: {}", e);
+                Ok::<_, ErrorObjectOwned>(e)
             }
-        }
-
-        // Restore the remaining events
-        while let Some((event, priority)) = temp_queue.pop() {
-            pq.push(event, priority);
-        }
-
-        if found {
-            event_ids.remove(&event_id);
-            Ok::<_, ErrorObjectOwned>("Event removed successfully".to_string())
-        } else {
-            Ok::<_, ErrorObjectOwned>("Event not found".to_string())
         }
     })?;
 
diff --git a/pallets/pallet-epoch/Cargo.toml b/pallets/pallet-epoch/Cargo.toml
index 555b063..8a00bf4 100644
--- a/pallets/pallet-epoch/Cargo.toml
+++ b/pallets/pallet-epoch/Cargo.toml
@@ -30,6 +30,11 @@ substrate-validator-set = { workspace = true }
 sp-state-machine = { workspace = true }
 fp-account = { workspace = true }
 pallet-transaction-payment = { 	workspace = true }
+hex = { workspace = true }
+blake2 = { workspace = true } 
+
+
+
 [dev-dependencies]
 scale-codec = { workspace = true }
 sp-consensus-aura = { git = "https://github.com/paritytech/polkadot-sdk", branch = "release-polkadot-v1.9.0", default-features = false }
@@ -42,6 +47,7 @@ pallet-balances = {workspace = true}
 [features]
 default = ["std"]
 std = [
+	"hex/std",
 	"scale-codec/std",
 	"frame-benchmarking/std",
 	"frame-support/std",
diff --git a/pallets/pallet-epoch/src/lib.rs b/pallets/pallet-epoch/src/lib.rs
index 8ef21ec..1b4b468 100644
--- a/pallets/pallet-epoch/src/lib.rs
+++ b/pallets/pallet-epoch/src/lib.rs
@@ -6,6 +6,7 @@ extern crate sp_std;
 use alloc::format;
 use alloc::{string::ToString, vec::Vec};
 use core::primitive::str;
+use frame_support::traits::StorageInstance;
 use frame_support::{
     dispatch::DispatchResult, pallet_prelude::*, storage::types::StorageMap,
     unsigned::TransactionSource, weights::Weight,
@@ -14,18 +15,19 @@ use frame_system::{offchain::*, pallet_prelude::*};
 use log::info;
 pub use pallet::*;
 use serde::{Deserialize, Deserializer, Serialize, Serializer};
+use sp_runtime::traits::IdentifyAccount;
 
 use sp_application_crypto::{AppCrypto, RuntimePublic};
 
+use scale_info::TypeInfo;
+use serde_json;
+use serde_json::Value;
 use sp_runtime::{
     app_crypto::AppPublic,
     codec::{Decode, Encode},
     offchain::{self as rt_offchain},
     traits::{Extrinsic as ExtrinsicT, ValidateUnsigned},
 };
-
-use scale_info::TypeInfo;
-use serde_json;
 use substrate_validator_set as validator_set;
 
 use pallet_session;
@@ -48,90 +50,101 @@ mod benchmarking;
 mod mock; // Add this line to declare the mock module
 pub mod weights;
 
-// Define the type for the maximum length
-pub struct MaxDataLength;
-
-impl MaxEncodedLen for CustomEvent {
-    fn max_encoded_len() -> usize {
-        u32::MAX as usize
-    }
-}
-
-impl MaxEncodedLen for CustomData {
-    fn max_encoded_len() -> usize {
-        u32::MAX as usize
-    }
-}
-
-impl MaxEncodedLen for EpochChangeData {
-    fn max_encoded_len() -> usize {
-        u32::MAX as usize
-    }
-}
-
-impl Get<u32> for MaxDataLength {
-    fn get() -> u32 {
-        1024 // Define your max length here
-    }
-}
-
-// Define the type for the maximum length
-pub struct MaxPayloadLength;
-
-impl Get<u32> for MaxPayloadLength {
-    fn get() -> u32 {
-        1024 // Define your max length here
-    }
-}
+mod limits;
+mod types;
+use limits::{MaxDataLength, MaxEventsLength, MaxPayloadLength, MaxRemoveEventsLength};
+use types::{CustomData, CustomEvent, EpochChangeData};
 
-pub struct MaxEventsLength;
-
-impl Get<u32> for MaxEventsLength {
-    fn get() -> u32 {
-        100 // Define your max length here
-    }
-}
-
-pub struct MaxRemoveEventsLength;
-
-impl Get<u32> for MaxRemoveEventsLength {
-    fn get() -> u32 {
-        100 // Define your max length here
-    }
-}
-
-#[derive(
-    Default, Deserialize, Serialize, Encode, Decode, Clone, Debug, PartialEq, Eq, TypeInfo,
-)]
-pub struct CustomEvent {
-    pub id: u64,
-    pub data: CustomData,
-    pub timestamp: u64,
-    pub block_height: u64,
-}
-
-#[derive(
-    Default, Deserialize, Serialize, Encode, Decode, Clone, Debug, PartialEq, Eq, TypeInfo,
-)]
-pub struct CustomData {
-    #[serde(rename = "type")]
-    pub event_type: String,
-    pub data: EpochChangeData,
-}
-
-#[derive(
-    Default, Deserialize, Serialize, Encode, Decode, Clone, Debug, PartialEq, Eq, TypeInfo,
-)]
-pub struct EpochChangeData {
-    pub last_epoch: u64,
-    pub last_blockhash: String,
-    pub last_slot: u64,
-    pub new_epoch: u64,
-    pub new_slot: u64,
-    pub new_blockhash: String,
-    pub epoch_nonce: String,
-    pub extra_entropy: Option<String>,
+#[derive(Serialize, Deserialize)]
+struct ProcessedEventResult {
+    events: Vec<Vec<CustomEvent>>,
+    duplicates: Vec<Vec<CustomEvent>>,
+    success: bool,
 }
+// // Define the type for the maximum length
+// pub struct MaxDataLength;
+
+// impl MaxEncodedLen for CustomEvent {
+//     fn max_encoded_len() -> usize {
+//         u32::MAX as usize
+//     }
+// }
+
+// impl MaxEncodedLen for CustomData {
+//     fn max_encoded_len() -> usize {
+//         u32::MAX as usize
+//     }
+// }
+
+// impl MaxEncodedLen for EpochChangeData {
+//     fn max_encoded_len() -> usize {
+//         u32::MAX as usize
+//     }
+// }
+
+// impl Get<u32> for MaxDataLength {
+//     fn get() -> u32 {
+//         1024 // Define your max length here
+//     }
+// }
+
+// // Define the type for the maximum length
+// pub struct MaxPayloadLength;
+
+// impl Get<u32> for MaxPayloadLength {
+//     fn get() -> u32 {
+//         1024 // Define your max length here
+//     }
+// }
+
+// pub struct MaxEventsLength;
+
+// impl Get<u32> for MaxEventsLength {
+//     fn get() -> u32 {
+//         100 // Define your max length here
+//     }
+// }
+
+// pub struct MaxRemoveEventsLength;
+
+// impl Get<u32> for MaxRemoveEventsLength {
+//     fn get() -> u32 {
+//         100 // Define your max length here
+//     }
+// }
+
+// #[derive(
+//     Default, Deserialize, Serialize, Encode, Decode, Clone, Debug, PartialEq, Eq, TypeInfo,
+// )]
+// pub struct CustomEvent {
+//     pub id: u64,
+//     pub data: CustomData,
+//     pub timestamp: u64,
+//     pub block_height: u64,
+// }
+
+// #[derive(
+//     Default, Deserialize, Serialize, Encode, Decode, Clone, Debug, PartialEq, Eq, TypeInfo,
+// )]
+// pub struct CustomData {
+//     #[serde(rename = "type")]
+//     pub event_type: String,
+//     pub data: EpochChangeData,
+// }
+
+// #[derive(
+//     Default, Deserialize, Serialize, Encode, Decode, Clone, Debug, PartialEq, Eq, TypeInfo,
+// )]
+// pub struct EpochChangeData {
+//     pub last_epoch: u64,
+//     pub last_blockhash: String,
+//     pub last_slot: u64,
+//     pub new_epoch: u64,
+//     pub new_slot: u64,
+//     pub new_blockhash: String,
+//     pub epoch_nonce: String,
+//     pub extra_entropy: Option<String>,
+// }
 #[derive(Debug, Deserialize)]
 struct JsonRpcResponse {
     events: Vec<Vec<CustomEvent>>, // Adjusted to directly hold the list of CustomEvent
@@ -177,6 +190,14 @@ pub mod pallet {
     pub type EventStorage<T: Config> =
         StorageMap<_, Blake2_128Concat, u64, CustomEvent, ValueQuery>;
 
+    #[pallet::storage]
+    #[pallet::getter(fn processed_transactions)]
+    pub type ProcessedTransactions<T: Config> =
+        StorageMap<_, Blake2_128Concat, Vec<u8>, bool, OptionQuery>;
+
+    #[pallet::storage]
+    #[pallet::getter(fn pending_events)]
+    pub type PendingEvents<T: Config> = StorageMap<_, Blake2_128Concat, u64, (), OptionQuery>;
     #[pallet::hooks]
     impl<T: Config> Hooks<BlockNumberFor<T>> for Pallet<T> {
         fn offchain_worker(block_number: BlockNumberFor<T>) {
@@ -212,8 +233,12 @@ pub mod pallet {
                         payload
                     );
 
+                    // Check if the transaction has already been processed
+                    if ProcessedTransactions::<T>::contains_key(&payload) {
+                        return InvalidTransaction::Stale.into();
+                    }
+
                     // Perform your validation logic here
-                    // For example, you can decode the payload and check its contents
                     match CustomEvent::decode(&mut &payload[..]) {
                         Ok(decoded_event) => {
                             log::info!("Decoded event from payload: {:?}", decoded_event);
@@ -253,71 +278,138 @@ pub mod pallet {
     where
         T: frame_system::offchain::SendTransactionTypes<Call<T>>,
     {
+        fn fetch_event_id(event_id: u64) -> Result<String, Error<T>> {
+            let url = "http://127.0.0.1:5555";
+            let request_body = serde_json::json!({
+                "jsonrpc": "2.0",
+                "method": "get_event_id",
+                "params": [event_id],
+                "id": 1
+            })
+            .to_string();
+
+            let request = rt_offchain::http::Request::post(url, vec![request_body.into_bytes()])
+                .add_header("Content-Type", "application/json")
+                .add_header("User-Agent", "SubstrateOffchainWorker")
+                .deadline(
+                    sp_io::offchain::timestamp().add(rt_offchain::Duration::from_millis(3000)),
+                )
+                .send()
+                .map_err(|_| <Error<T>>::HttpFetchingError)?;
+
+            let response = request
+                .try_wait(
+                    sp_io::offchain::timestamp().add(rt_offchain::Duration::from_millis(3000)),
+                )
+                .map_err(|_| <Error<T>>::HttpFetchingError)?
+                .map_err(|_| <Error<T>>::HttpFetchingError)?;
+
+            if response.code != 200 {
+                log::error!("Unexpected response code: {}", response.code);
+                return Err(<Error<T>>::HttpFetchingError);
+            }
+
+            let body = response.body().collect::<Vec<u8>>();
+            let body_str = sp_std::str::from_utf8(&body).map_err(|_| <Error<T>>::InvalidUtf8)?;
+
+            let json: serde_json::Value =
+                serde_json::from_str(body_str).map_err(|_| <Error<T>>::JsonSerializationError)?;
+            if json["success"].as_bool().unwrap_or(false) {
+                if let Some(event_id) = json["event_id"].as_str() {
+                    return Ok(event_id.to_string());
+                }
+            }
+
+            Err(<Error<T>>::InvalidResponseFormat)
+        }
         fn fetch_and_process_events_from_queue() -> Result<(), Error<T>> {
             log::info!("Fetching all events from the queue");
 
-            // Fetch all events as a JSON response
             let response = Self::process_real_event()?;
+            let response_data: ProcessedEventResult =
+                serde_json::from_slice(&response).map_err(|e| {
+                    log::error!("Failed to deserialize events: {:?}", e);
+                    <Error<T>>::JsonSerializationError
+                })?;
 
-            // Deserialize the JSON response into the expected structure
-            let events: Vec<Vec<CustomEvent>> = serde_json::from_slice(&response).map_err(|e| {
-                log::error!("Failed to deserialize events: {:?}", e);
-                <Error<T>>::JsonSerializationError
-            })?;
+            let events = response_data.events;
+            let duplicates = response_data.duplicates;
 
-            // Process each event
-            for event_group in events.iter() {
-                for event in event_group.iter() {
+            for event_group in events.into_iter().chain(duplicates.into_iter()) {
+                for event in event_group {
                     log::info!("Processing event: {:?}", event);
 
-                    // Encode the event payload
                     let payload = event.encode();
-
-                    // Submit the encoded payload as an unsigned transaction
-                    log::info!(
-                        "Submitting unsigned transaction with payload: {:?}",
-                        payload
-                    );
-
-                    // Create and submit the call
-                    let call = Call::<T>::submit_encoded_payload {
-                        payload: payload.clone(),
-                    };
-
-                    match frame_system::offchain::SubmitTransaction::<T, Call<T>>::submit_unsigned_transaction(call.into()) {
-                Ok(_) => log::info!("Transaction submitted successfully"),
-                Err(e) => log::error!("Error submitting unsigned transaction: {:?}", e),
-            }
+                    if !ProcessedTransactions::<T>::contains_key(&payload) {
+                        match Self::submit_unsigned_transaction(payload.clone(), event.id) {
+                            Ok(_) => {
+                                log::info!(
+                                    "Transaction submitted successfully for event ID: {}",
+                                    event.id
+                                );
+                            }
+                            Err(e) => {
+                                log::error!("Error submitting unsigned transaction: {:?}", e);
+                            }
+                        }
+                    } else {
+                        log::info!("Event {} is already processed", event.id);
+                    }
                 }
             }
 
-            // Return Ok(()) at the end of the function
             Ok(())
         }
     }
 
     use alloc::format;
 
-    impl<T: Config> Pallet<T>
-    where
-        T: frame_system::offchain::SendTransactionTypes<Call<T>>,
-    {
-        fn submit_unsigned_transaction(payload: Vec<u8>) -> Result<(), &'static str> {
+    impl<T: Config> Pallet<T> {
+        fn submit_unsigned_transaction(
+            payload: Vec<u8>,
+            event_id: u64,
+        ) -> Result<(), &'static str> {
             log::info!(
-                "Creating Call::submit_encoded_payload with payload: {:?}",
-                payload
+                "Attempting to submit unsigned transaction with payload: {:?} and event_id: {}",
+                payload,
+                event_id
             );
 
-            let call = Call::submit_encoded_payload { payload };
+            if ProcessedTransactions::<T>::contains_key(&payload) {
+                log::info!(
+                    "Transaction with payload {:?} is already processed",
+                    payload
+                );
+                return Ok(());
+            }
 
-            log::info!("Submitting unsigned transaction with call: {:?}", call);
-            frame_system::offchain::SubmitTransaction::<T, Call<T>>::submit_unsigned_transaction(
-                call.into(),
-            )
-            .map_err(|e| {
-                log::error!("Failed to submit unsigned transaction: {:?}", e);
-                "Failed to submit unsigned transaction"
-            })
+            if PendingEvents::<T>::contains_key(event_id) {
+                log::info!("Event {} is already being processed", event_id);
+                return Ok(());
+            }
+
+            PendingEvents::<T>::insert(event_id, ());
+
+            let call = Call::submit_encoded_payload {
+                payload: payload.clone(),
+            };
+
+            log::info!("Submitting call: {:?}", call);
+
+            match frame_system::offchain::SubmitTransaction::<T, Call<T>>::submit_unsigned_transaction(call.into()) {
+                Ok(_) => {
+                    log::info!("Transaction submitted successfully");
+                    ProcessedTransactions::<T>::insert(payload, true);
+                    EventStorage::<T>::remove(event_id);
+                    PendingEvents::<T>::remove(event_id);
+                    Ok(())
+                },
+                Err(e) => {
+                    log::error!("Failed to submit unsigned transaction: {:?}", e);
+                    PendingEvents::<T>::remove(event_id);
+                    Err("Failed to submit unsigned transaction")
+                }
+            }
         }
     }
 
@@ -334,7 +426,7 @@ pub mod pallet {
             const HTTP_HEADER_CONTENT_TYPE: &str = "Content-Type";
             const CONTENT_TYPE_JSON: &str = "application/json";
             const FETCH_TIMEOUT_PERIOD: u64 = 3000; // in milliseconds
-
+    
             // Create the JSON-RPC request payload
             let json_payload = serde_json::json!({
                 "jsonrpc": "2.0",
@@ -344,7 +436,7 @@ pub mod pallet {
             })
             .to_string()
             .into_bytes();
-
+    
             // Initiate an external HTTP POST request
             let request =
                 rt_offchain::http::Request::post(HTTP_REMOTE_REQUEST, vec![&json_payload])
@@ -356,7 +448,7 @@ pub mod pallet {
                     )
                     .send()
                     .map_err(|_| <Error<T>>::HttpFetchingError)?;
-
+    
             let response = request
                 .try_wait(
                     sp_io::offchain::timestamp()
@@ -364,7 +456,7 @@ pub mod pallet {
                 )
                 .map_err(|_| <Error<T>>::HttpFetchingError)?
                 .map_err(|_| <Error<T>>::HttpFetchingError)?;
-
+    
             if response.code != 200 {
                 log::error!("Non-200 response code: {}", response.code);
                 return Err(<Error<T>>::HttpFetchingError);
@@ -374,44 +466,45 @@ pub mod pallet {
                 log::error!("Failed to parse response body as UTF-8: {:?}", e);
                 <Error<T>>::InvalidUtf8
             })?;
-
+    
             log::info!("HTTP Response Body: {}", json_string);
-
+    
             // Parse the outer JSON-RPC response
             let rpc_response: serde_json::Value =
                 serde_json::from_str(&json_string).map_err(|e| {
                     log::error!("Failed to parse JSON-RPC response: {:?}", e);
                     <Error<T>>::InvalidResponseFormat
                 })?;
-
+    
             log::info!("RPC Response: {:?}", rpc_response);
-
+    
             // Extract the "result" field, which is a stringified JSON
             let result_str = rpc_response["result"].as_str().ok_or_else(|| {
                 log::error!("Failed to extract result string");
                 <Error<T>>::InvalidResponseFormat
             })?;
-
+    
             log::info!("Result string: {}", result_str);
-
-            // Parse the inner JSON (the actual event data)
-            let inner_response: serde_json::Value =
-                serde_json::from_str(result_str).map_err(|e| {
-                    log::error!("Failed to parse inner JSON response: {:?}", e);
-                    <Error<T>>::InvalidResponseFormat
-                })?;
-
+    
+            let inner_response: serde_json::Value = serde_json::from_str(result_str).map_err(|e| {
+                log::error!("Failed to parse inner JSON response: {:?}", e);
+                <Error<T>>::InvalidResponseFormat
+            })?;
+    
             log::info!("Inner response: {:?}", inner_response);
-
-            // Extract the events array
+    
+            // Extract the events and duplicates arrays
             let events = inner_response["events"].as_array().ok_or_else(|| {
                 log::error!("Failed to extract events array");
                 <Error<T>>::InvalidResponseFormat
             })?;
-
+    
+            // let duplicates = inner_response["duplicates"].as_array().unwrap_or(&Vec::new());
+            let binding = Vec::new();
+            let duplicates = inner_response["duplicates"].as_array().unwrap_or(&binding);
             log::info!("Events: {:?}", events);
-
-            // Process each event
+            log::info!("Duplicates: {:?}", duplicates);
+    
             let mut processed_events = Vec::new();
             for (i, event_group) in events.iter().enumerate() {
                 let mut processed_group = Vec::new();
@@ -424,67 +517,127 @@ pub mod pallet {
                     .iter()
                     .enumerate()
                 {
-                    log::info!("Processing event {}.{}: {:?}", i, j, event);
-
-                    // Check if the event is a JSON object
-                    if let Some(event_obj) = event.as_object() {
-                        let id = event_obj["id"].as_u64().ok_or_else(|| {
-                            log::error!("Failed to extract id from event {}.{}", i, j);
-                            <Error<T>>::InvalidResponseFormat
-                        })?;
-                        let timestamp = event_obj["timestamp"].as_u64().ok_or_else(|| {
-                            log::error!("Failed to extract timestamp from event {}.{}", i, j);
-                            <Error<T>>::InvalidResponseFormat
-                        })?;
-                        let block_height = event_obj["block_height"].as_u64().ok_or_else(|| {
-                            log::error!("Failed to extract block_height from event {}.{}", i, j);
-                            <Error<T>>::InvalidResponseFormat
-                        })?;
-
-                        // Parse the data field, which is a stringified JSON
-                        let data_str = event_obj["data"].as_str().ok_or_else(|| {
-                            log::error!("Failed to extract data string from event {}.{}", i, j);
-                            <Error<T>>::InvalidResponseFormat
-                        })?;
-
-                        log::info!("Data string for event {}.{}: {}", i, j, data_str);
-
-                        let data: CustomData = serde_json::from_str(data_str).map_err(|e| {
-                            log::error!(
-                                "Failed to parse event data for event {}.{}: {:?}",
-                                i,
-                                j,
-                                e
-                            );
-                            <Error<T>>::JsonSerializationError
-                        })?;
-
-                        let custom_event = CustomEvent {
-                            id,
-                            data,
-                            timestamp,
-                            block_height,
-                        };
-
-                        log::info!("Processed event {}.{}: {:?}", i, j, custom_event);
-
+                    if let Some(custom_event) = Self::process_event(event, i, j, "event")? {
                         processed_group.push(custom_event);
-                    } else {
-                        log::warn!("Skipping non-object event {}.{}: {:?}", i, j, event);
                     }
                 }
                 processed_events.push(processed_group);
             }
-
-            // Serialize the processed events back to JSON
-            let events_json = serde_json::to_string(&processed_events).map_err(|e| {
-                log::error!("Failed to serialize processed events: {:?}", e);
+    
+            // Process duplicates
+            let mut processed_duplicates = Vec::new();
+            for (i, duplicate_group) in duplicates.iter().enumerate() {
+                let mut processed_group = Vec::new();
+                for (j, duplicate) in duplicate_group
+                    .as_array()
+                    .ok_or_else(|| {
+                        log::error!("Duplicate group {} is not an array", i);
+                        <Error<T>>::InvalidResponseFormat
+                    })?
+                    .iter()
+                    .enumerate()
+                {
+                    if let Some(custom_event) = Self::process_event(duplicate, i, j, "duplicate")? {
+                        processed_group.push(custom_event);
+                    }
+                }
+                processed_duplicates.push(processed_group);
+            }
+    
+            // Combine processed events and duplicates
+            let result = ProcessedEventResult {
+                events: processed_events,
+                duplicates: processed_duplicates,
+                success: true,
+            };
+    
+            // Serialize the result back to JSON
+            let result_json = serde_json::to_string(&result).map_err(|e| {
+                log::error!("Failed to serialize processed result: {:?}", e);
                 <Error<T>>::JsonSerializationError
             })?;
+    
+            log::info!("Processed result JSON: {}", result_json);
+    
+            Ok(result_json.into_bytes())
+        }
+
+        fn process_event(
+            event: &serde_json::Value,
+            i: usize,
+            j: usize,
+            event_type: &str,
+        ) -> Result<Option<CustomEvent>, Error<T>> {
+            log::info!("Processing {} {}.{}: {:?}", event_type, i, j, event);
+
+            if let Some(event_obj) = event.as_object() {
+                let id = event_obj["id"].as_u64().ok_or_else(|| {
+                    log::error!("Failed to extract id from {} {}.{}", event_type, i, j);
+                    <Error<T>>::InvalidResponseFormat
+                })?;
+                let timestamp = event_obj["timestamp"].as_u64().ok_or_else(|| {
+                    log::error!(
+                        "Failed to extract timestamp from {} {}.{}",
+                        event_type,
+                        i,
+                        j
+                    );
+                    <Error<T>>::InvalidResponseFormat
+                })?;
+                let block_height = event_obj["block_height"].as_u64().ok_or_else(|| {
+                    log::error!(
+                        "Failed to extract block_height from {} {}.{}",
+                        event_type,
+                        i,
+                        j
+                    );
+                    <Error<T>>::InvalidResponseFormat
+                })?;
+
+                let data_str = event_obj["data"].as_str().ok_or_else(|| {
+                    log::error!(
+                        "Failed to extract data string from {} {}.{}",
+                        event_type,
+                        i,
+                        j
+                    );
+                    <Error<T>>::InvalidResponseFormat
+                })?;
+
+                log::info!("Data string for {} {}.{}: {}", event_type, i, j, data_str);
+
+                let data: CustomData = serde_json::from_str(data_str).map_err(|e| {
+                    log::error!(
+                        "Failed to parse {} data for {} {}.{}: {:?}",
+                        event_type,
+                        event_type,
+                        i,
+                        j,
+                        e
+                    );
+                    <Error<T>>::JsonSerializationError
+                })?;
 
-            log::info!("Processed events JSON: {}", events_json);
+                let custom_event = CustomEvent {
+                    id,
+                    data,
+                    timestamp,
+                    block_height,
+                };
 
-            Ok(events_json.into_bytes())
+                log::info!("Processed {} {}.{}: {:?}", event_type, i, j, custom_event);
+
+                Ok(Some(custom_event))
+            } else {
+                log::warn!(
+                    "Skipping non-object {} {}.{}: {:?}",
+                    event_type,
+                    i,
+                    j,
+                    event
+                );
+                Ok(None)
+            }
         }
         // Step 5: Message Cleanup
         fn cleanup_processed_events() {
@@ -759,6 +912,28 @@ pub mod pallet {
             log::info!("Processing decoded call: {:?}", call);
             Self::process_decoded_call(call)
         }
+        #[pallet::call_index(3)]
+        #[pallet::weight(10_000)]
+        pub fn remove_event_from_storage(origin: OriginFor<T>, event_id: u64) -> DispatchResult {
+            let _who = ensure_signed(origin)?;
+            ensure!(
+                EventStorage::<T>::contains_key(event_id),
+                Error::<T>::EventNotFound
+            );
+
+            EventStorage::<T>::remove(event_id);
+
+            Self::deposit_event(Event::EventRemoved { event_id });
+            Ok(())
+        }
+        #[pallet::call_index(4)]
+        #[pallet::weight(10_000)]
+        pub fn store_event_id(origin: OriginFor<T>, event_id: String) -> DispatchResult {
+            let _who = ensure_none(origin)?;
+            // Implement the logic to store the event ID
+            log::info!("Storing event ID: {:?}", event_id);
+            Ok(())
+        }
     }
 
     #[pallet::error]
@@ -781,6 +956,7 @@ pub mod pallet {
     #[pallet::generate_deposit(pub(super) fn deposit_event)]
     pub enum Event<T: Config> {
         DataFetchedSuccessfully,
+        EventRemoved { event_id: u64 },
     }
 
     #[pallet::type_value]
diff --git a/pallets/pallet-epoch/src/lib62224.rs b/pallets/pallet-epoch/src/lib62224.rs
deleted file mode 100644
index cfdd609..0000000
--- a/pallets/pallet-epoch/src/lib62224.rs
+++ /dev/null
@@ -1,791 +0,0 @@
-#![cfg_attr(not(feature = "std"), no_std)]
-extern crate alloc;
-#[cfg_attr(feature = "std", macro_use)]
-extern crate serde;
-extern crate sp_std;
-use alloc::{string::ToString, vec::Vec};
-use log::info;
-
-pub use pallet::*;
-
-use frame_support::{
-    dispatch::DispatchResult, pallet_prelude::*, storage::types::StorageMap,
-    unsigned::TransactionSource, weights::Weight,
-};
-use frame_system::{offchain::*, pallet_prelude::*};
-
-use sp_application_crypto::{AppCrypto, RuntimePublic};
-
-use sp_runtime::{
-    app_crypto::AppPublic,
-    codec::{Decode, Encode},
-    offchain::{self as rt_offchain},
-    traits::{Extrinsic as ExtrinsicT, ValidateUnsigned},
-    Deserialize, Serialize,
-};
-
-use scale_info::TypeInfo;
-use serde_json;
-use substrate_validator_set as validator_set;
-
-use pallet_session;
-
-use frame_support::pallet_prelude::{BoundedVec, Get, MaxEncodedLen};
-use sp_runtime::AccountId32;
-use sp_std::prelude::*;
-
-use sp_application_crypto::sr25519;
-
-use sp_application_crypto::ed25519;
-
-use scale_info::prelude::string::String;
-#[cfg(test)]
-mod tests;
-
-#[cfg(feature = "runtime-benchmarks")]
-mod benchmarking;
-#[cfg(test)]
-mod mock; // Add this line to declare the mock module
-pub mod weights;
-
-// Define the type for the maximum length
-pub struct MaxDataLength;
-
-impl Get<u32> for MaxDataLength {
-    fn get() -> u32 {
-        1024 // Define your max length here
-    }
-}
-
-// Define the type for the maximum length
-pub struct MaxPayloadLength;
-
-impl Get<u32> for MaxPayloadLength {
-    fn get() -> u32 {
-        1024 // Define your max length here
-    }
-}
-
-pub struct MaxEventsLength;
-
-impl Get<u32> for MaxEventsLength {
-    fn get() -> u32 {
-        100 // Define your max length here
-    }
-}
-
-pub struct MaxRemoveEventsLength;
-
-impl Get<u32> for MaxRemoveEventsLength {
-    fn get() -> u32 {
-        100 // Define your max length here
-    }
-}
-
-#[derive(
-    Default,
-    Deserialize,
-    Serialize,
-    Encode,
-    Decode,
-    Clone,
-    PartialEq,
-    Eq,
-    TypeInfo,
-    MaxEncodedLen,
-    RuntimeDebug,
-)]
-pub struct CustomData(pub BoundedVec<u8, MaxDataLength>);
-
-impl CustomData {
-    pub fn is_empty(&self) -> bool {
-        self.0.is_empty()
-    }
-}
-
-#[derive(
-    Default,
-    Deserialize,
-    Serialize,
-    Encode,
-    Decode,
-    Clone,
-    PartialEq,
-    Eq,
-    TypeInfo,
-    MaxEncodedLen,
-    RuntimeDebug,
-)]
-pub struct CustomEvent {
-    pub id: u64,
-    pub data: CustomData,
-    pub timestamp: u64,
-    pub block_height: u64,
-    pub last_epoch: u64,
-    pub last_blockhash: BoundedVec<u8, MaxDataLength>,
-    pub last_slot: u64,
-    pub new_epoch: u64,
-    pub new_slot: u64,
-    pub new_blockhash: BoundedVec<u8, MaxDataLength>,
-    pub epoch_nonce: BoundedVec<u8, MaxDataLength>,
-    pub extra_entropy: Option<BoundedVec<u8, MaxDataLength>>,
-}
-
-impl CustomEvent {
-    fn new(
-        id: u64,
-        data: Vec<u8>,
-        timestamp: u64,
-        block_height: u64,
-        last_epoch: u64,
-        last_blockhash: Vec<u8>,
-        last_slot: u64,
-        new_epoch: u64,
-        new_slot: u64,
-        new_blockhash: Vec<u8>,
-        epoch_nonce: Vec<u8>,
-        extra_entropy: Option<Vec<u8>>,
-    ) -> Result<Self, &'static str> {
-        Ok(CustomEvent {
-            id,
-            data: CustomData(
-                BoundedVec::try_from(data).map_err(|_| "Data exceeds maximum length")?,
-            ),
-            timestamp,
-            block_height,
-            last_epoch,
-            last_blockhash: BoundedVec::try_from(last_blockhash)
-                .map_err(|_| "Last blockhash exceeds maximum length")?,
-            last_slot,
-            new_epoch,
-            new_slot,
-            new_blockhash: BoundedVec::try_from(new_blockhash)
-                .map_err(|_| "New blockhash exceeds maximum length")?,
-            epoch_nonce: BoundedVec::try_from(epoch_nonce)
-                .map_err(|_| "Epoch nonce exceeds maximum length")?,
-            extra_entropy: extra_entropy
-                .map(|e| {
-                    BoundedVec::try_from(e).map_err(|_| "Extra entropy exceeds maximum length")
-                })
-                .transpose()?,
-        })
-    }
-}
-
-#[frame_support::pallet]
-pub mod pallet {
-    use super::*;
-    use sp_core::ByteArray;
-
-    #[pallet::config]
-    pub trait Config:
-        frame_system::Config
-        + CreateSignedTransaction<Call<Self>>
-        + validator_set::Config
-        + pallet_session::Config
-    {
-        type RuntimeEvent: From<Event<Self>> + IsType<<Self as frame_system::Config>::RuntimeEvent>;
-        type WeightInfo: WeightInfo;
-        type AuthorityId: AppPublic + From<sp_core::sr25519::Public>;
-        type ValidatorId: Clone
-            + From<Self::AccountId>
-            + Into<AccountId32>
-            + From<<Self as pallet_session::Config>::ValidatorId>;
-        type AccountId32Convert: From<AccountId32> + Into<Self::AccountId>;
-        type Call: From<Call<Self>>;
-        type UnsignedPriority: Get<u64>;
-    }
-
-    #[pallet::pallet]
-    #[pallet::without_storage_info]
-    pub struct Pallet<T>(_);
-
-    #[pallet::storage]
-    #[pallet::getter(fn event_storage)]
-    pub type EventStorage<T: Config> =
-        StorageMap<_, Blake2_128Concat, u64, CustomEvent, ValueQuery>;
-
-    #[pallet::hooks]
-    impl<T: Config> Hooks<BlockNumberFor<T>> for Pallet<T> {
-        fn offchain_worker(block_number: BlockNumberFor<T>) {
-            // Create and submit an inclusion transaction
-            if let Err(e) = Self::create_inclusion_transaction() {
-                log::error!("Error creating inclusion transaction: {:?}", e);
-            }
-        }
-    }
-
-    #[pallet::validate_unsigned]
-    impl<T: Config> ValidateUnsigned for Pallet<T> {
-        type Call = Call<T>;
-
-        fn validate_unsigned(source: TransactionSource, call: &Self::Call) -> TransactionValidity {
-            log::info!("Validating unsigned transaction: {:?}", call);
-
-            // Only accept transactions from local or in-bundle sources
-            if !matches!(
-                source,
-                TransactionSource::Local | TransactionSource::InBlock
-            ) {
-                return InvalidTransaction::Call.into();
-            }
-
-            match call {
-                Call::process_epoch_event { nonce, payload } => {
-                    log::info!("Validating process_epoch_event with nonce: {}", nonce);
-                    // Perform your validation logic here
-                    ValidTransaction::with_tag_prefix("InclusionTransaction")
-                        .priority(TransactionPriority::max_value())
-                        .longevity(TransactionLongevity::max_value())
-                        .propagate(true)
-                        .build()
-                }
-                _ => InvalidTransaction::Call.into(),
-            }
-        }
-    }
-
-    impl<T: Config> Pallet<T>
-    where
-        <T as pallet::Config>::ValidatorId:
-            Clone + Into<AccountId32> + From<<T as pallet_session::Config>::ValidatorId>,
-        <T as pallet_session::Config>::ValidatorId: Clone,
-    {
-        fn convert_session_validator_id_to_pallet_validator_id(
-            key: <T as pallet_session::Config>::ValidatorId,
-        ) -> <T as pallet::Config>::ValidatorId {
-            key.into()
-        }
-    }
-    use alloc::format;
-    impl<T: Config> Pallet<T>
-    where
-        T: frame_system::offchain::SendTransactionTypes<Call<T>>,
-    {
-        
-
-        fn create_inclusion_transaction() -> Result<(), &'static str> {
-            log::info!("Creating an inclusion transaction with a stub event payload");
-        
-            // Create a unique nonce
-            let nonce: u64 = sp_io::offchain::timestamp().unix_millis();
-        
-            // Fetch the latest event from the queue
-            let latest_event = {
-                // Fetch all events
-                let events = Self::fetch_all_events().map_err(|e| {
-                    log::error!("Error fetching events: {:?}", e);
-                    "HttpFetchingError"
-                })?;
-        
-                // Check if there are any events to process
-                if events.is_empty() {
-                    log::info!("No events to process.");
-                    return Err("No events in the queue");
-                }
-        
-                // Get the latest event
-                events.last().ok_or("No events in the queue")?.clone()
-            };
-            log::info!("Latest event before encoding: {:?}", latest_event.clone());
-        
-            // Create a larger payload by adding mock data
-            let mut stub_event_data = latest_event.encode();
-            let additional_data = vec![0u8; 1024]; // 1 KB of additional data
-            stub_event_data.extend(additional_data);
-        
-            log::info!("Encoded payload: {:?}", stub_event_data);
-            log::info!("Payload size: {}", stub_event_data.len());
-        
-            // Create the call with the nonce and payload
-            let call = Call::<T>::process_epoch_event {
-                nonce,
-                payload: stub_event_data.clone(), // Clone for logging
-            };
-            log::info!("Submitting call with payload: {:?}", stub_event_data);
-        
-            // Submit the transaction
-            match frame_system::offchain::SubmitTransaction::<T, Call<T>>::submit_unsigned_transaction(call.into()) {
-                Ok(_) => log::info!("Stub event transaction submitted successfully"),
-                Err(e) => log::error!("Error submitting stub event transaction: {:?}", e),
-            }
-        
-            Ok(())
-        }
-        
-        
-    }
-
-    impl<T: Config> Pallet<T>
-    where
-        T: frame_system::offchain::SendTransactionTypes<Call<T>>,
-    {
-        fn submit_unsigned_transaction(payload: Vec<u8>) -> Result<(), &'static str> {
-            log::info!(
-                "Creating Call::submit_encoded_payload with payload: {:?}",
-                payload
-            );
-
-            let call = Call::submit_encoded_payload { payload };
-
-            log::info!("Submitting unsigned transaction with call: {:?}", call);
-            frame_system::offchain::SubmitTransaction::<T, Call<T>>::submit_unsigned_transaction(
-                call.into(),
-            )
-            .map_err(|e| {
-                log::error!("Failed to submit unsigned transaction: {:?}", e);
-                "Failed to submit unsigned transaction"
-            })
-        }
-    }
-
-    impl<T: Config> Pallet<T> {
-        fn fetch_all_events() -> Result<BoundedVec<u8, MaxDataLength>, Error<T>> {
-            const HTTP_REMOTE_REQUEST: &str = "http://127.0.0.1:5555";
-            const HTTP_HEADER_USER_AGENT: &str = "SubstrateOffchainWorker";
-            const HTTP_HEADER_CONTENT_TYPE: &str = "Content-Type";
-            const CONTENT_TYPE_JSON: &str = "application/json";
-            const FETCH_TIMEOUT_PERIOD: u64 = 3000; // in milliseconds
-
-            // Create the JSON-RPC request payload
-            let json_payload = serde_json::json!({
-                "jsonrpc": "2.0",
-                "method": "list_all_events",
-                "params": [],
-                "id": 1
-            })
-            .to_string()
-            .into_bytes();
-
-            // Initiate an external HTTP POST request
-            let request =
-                rt_offchain::http::Request::post(HTTP_REMOTE_REQUEST, vec![&json_payload])
-                    .add_header("User-Agent", HTTP_HEADER_USER_AGENT)
-                    .add_header(HTTP_HEADER_CONTENT_TYPE, CONTENT_TYPE_JSON)
-                    .deadline(
-                        sp_io::offchain::timestamp()
-                            .add(rt_offchain::Duration::from_millis(FETCH_TIMEOUT_PERIOD)),
-                    )
-                    .send()
-                    .map_err(|_| <Error<T>>::HttpFetchingError)?;
-
-            let response = request
-                .try_wait(
-                    sp_io::offchain::timestamp()
-                        .add(rt_offchain::Duration::from_millis(FETCH_TIMEOUT_PERIOD)),
-                )
-                .map_err(|_| <Error<T>>::HttpFetchingError)?
-                .map_err(|_| <Error<T>>::HttpFetchingError)?;
-
-            if response.code != 200 {
-                log::error!("Non-200 response code: {}", response.code);
-                return Err(<Error<T>>::HttpFetchingError);
-            }
-
-            let body = response.body().collect::<Vec<u8>>();
-            let json_string = String::from_utf8(body).map_err(|e| {
-                log::error!("Failed to parse response body as UTF-8: {:?}", e);
-                <Error<T>>::InvalidUtf8
-            })?;
-
-            log::info!("HTTP Response Body: {}", json_string);
-
-            let parsed_json: serde_json::Value =
-                serde_json::from_str(&json_string).map_err(|e| {
-                    log::error!("Failed to parse JSON response: {:?}", e);
-                    <Error<T>>::InvalidResponseFormat
-                })?;
-
-            if let Some(events_str) = parsed_json.get("result").and_then(|result| result.as_str()) {
-                let events_bytes = events_str.as_bytes().to_vec();
-                let bounded_body: BoundedVec<u8, MaxDataLength> =
-                    BoundedVec::try_from(events_bytes).map_err(|_| {
-                        log::error!("Failed to convert to BoundedVec");
-                        <Error<T>>::HttpFetchingError
-                    })?;
-
-                return Ok(bounded_body);
-            }
-
-            log::error!("Invalid JSON-RPC format");
-            Err(<Error<T>>::InvalidResponseFormat)
-        }
-    }
-
-    impl<T: Config> Pallet<T>
-    where
-        <T as pallet::Config>::ValidatorId:
-            Clone + Into<AccountId32> + From<<T as pallet_session::Config>::ValidatorId>,
-        <T as pallet_session::Config>::ValidatorId: Clone,
-        T::AuthorityId: AppCrypto + From<sp_core::sr25519::Public>,
-    {
-        // Step 5: Message Cleanup
-        fn cleanup_processed_events() {
-            // Remove events from storage that have been included in the blockchain
-            for (event_id, _) in EventStorage::<T>::iter() {
-                EventStorage::<T>::remove(event_id);
-            }
-        }
-
-        fn fetch_local_keys() -> Vec<T::AuthorityId> {
-            let key_type_id = T::AuthorityId::ID;
-            sp_io::crypto::sr25519_public_keys(key_type_id)
-                .into_iter()
-                .map(|key| T::AuthorityId::from(key))
-                .collect()
-        }
-        // Function to convert ValidatorId to AuthorityId
-        fn convert_validator_id_to_authority_id(
-            key: <T as pallet::Config>::ValidatorId,
-        ) -> Result<T::AuthorityId, &'static str> {
-            // Convert ValidatorId to AccountId32
-            let account_id32: AccountId32 = key.into();
-
-            // Retrieve the public keys and find the matching one
-            let public_key = sp_io::crypto::sr25519_public_keys(T::AuthorityId::ID)
-                .into_iter()
-                .find(|pk| AccountId32::from(*pk) == account_id32)
-                .ok_or("Failed to find AuthorityId for the given ValidatorId")?;
-
-            // Convert the public key to AuthorityId
-            Ok(T::AuthorityId::from(public_key))
-        }
-
-        // Function to convert AuthorityId to AccountId32
-        fn convert_to_account_id32(key: T::AuthorityId) -> AccountId32 {
-            let public_key = key.to_raw_vec();
-            AccountId32::from_slice(&public_key)
-                .expect("Failed to convert AuthorityId to AccountId32")
-        }
-
-        fn is_leader() -> bool {
-            // Fetch the current set of validators
-            let validators = validator_set::Validators::<T>::get();
-            // Get the current session index
-            let current_index = pallet_session::Pallet::<T>::current_index();
-
-            if let Some(session_leader) = validators.get(current_index as usize % validators.len())
-            {
-                // // Convert session's ValidatorId to pallet's ValidatorId
-                let leader = Self::convert_session_validator_id_to_pallet_validator_id(
-                    session_leader.clone(),
-                );
-
-                // // Convert leader to AuthorityId
-                if let Ok(leader_authority_id) = Self::convert_validator_id_to_authority_id(leader)
-                {
-                    let local_keys = Self::fetch_local_keys();
-
-                    for local_key in local_keys {
-                        if local_key == leader_authority_id {
-                            return true;
-                        }
-                    }
-                }
-            }
-            false
-        }
-        // Step 4: Message Validation
-        fn validate_and_process_event(event: CustomEvent) -> Result<(), Error<T>> {
-            // Validate the event data
-            if event.timestamp == 0 || event.block_height == 0 {
-                return Err(Error::<T>::InvalidEventData);
-            }
-
-            if event.data.0.is_empty() {
-                return Err(Error::<T>::InvalidEventData);
-            }
-
-            // Process the event (e.g., store in mempool)
-            Self::store_event_in_mempool(event.clone()).map_err(|_| Error::<T>::StorageOverflow)?;
-
-            // Encode the event payload
-            let payload = event.encode();
-
-            // Submit the encoded payload as an unsigned transaction
-            log::info!(
-                "Submitting unsigned transaction with payload: {:?}",
-                payload
-            );
-            // Self::submit_unsigned_transaction(payload).map_err(|e| {
-            //     log::error!("Error submitting unsigned transaction: {:?}", e);
-            //     Error::<T>::TransactionSubmissionError
-            // })?;
-
-            Ok(())
-        }
-
-        // Step 2: Message Storage
-        fn store_event_in_mempool(event: CustomEvent) -> Result<(), &'static str> {
-            EventStorage::<T>::insert(event.id, event);
-            Ok(())
-        }
-
-        fn fetch_and_process_events_from_queue() -> Result<(), Error<T>> {
-            log::info!("Fetching all events from the queue");
-
-            // Fetch all events
-            let response = Self::fetch_all_events()?;
-            let bounded_events: BoundedVec<CustomEvent, MaxEventsLength> =
-                serde_json::from_slice(&response).map_err(|_| <Error<T>>::HttpFetchingError)?;
-
-            // Check if there are any events to process
-            if bounded_events.is_empty() {
-                log::info!("No events to process.");
-                return Ok(());
-            }
-
-            // Process all events if node is the leader
-            if Self::is_leader() {
-                log::info!("Node is the leader, processing events");
-
-                let mut events_to_remove: BoundedVec<u64, MaxRemoveEventsLength> =
-                    BoundedVec::default();
-
-                for event in bounded_events.iter() {
-                    log::info!("Validating and processing event: {:?}", event);
-
-                    // Validate and process the event
-                    Self::validate_and_process_event(event.clone())?;
-
-                    // Encode the event payload
-                    let payload = event.encode();
-
-                    // Submit the encoded payload as an unsigned transaction
-                    log::info!(
-                        "Submitting unsigned transaction with payload: {:?}",
-                        payload
-                    );
-
-                    // Decode the payload to create a call
-                    let call = match Call::<T>::decode(&mut &payload[..]) {
-                        Ok(call) => call,
-                        Err(_) => {
-                            log::error!("Failed to decode the provided transaction payload");
-                            continue;
-                        }
-                    };
-
-                    // Submit the transaction
-                    match frame_system::offchain::SubmitTransaction::<T, Call<T>>::submit_unsigned_transaction(
-                        call.into(),
-                    ) {
-                        Ok(_) => {
-                            // If submission is successful, mark event for removal
-                            log::info!(
-                                "Transaction submitted successfully, marking event for removal: {:?}",
-                                event.id
-                            );
-                            events_to_remove
-                                .try_push(event.id)
-                                .map_err(|_| <Error<T>>::StorageOverflow)?;
-                        },
-                        Err(e) => {
-                            log::error!("Error submitting unsigned transaction: {:?}", e);
-                        }
-                    }
-                }
-
-                // Remove processed events from the storage
-                for event_id in events_to_remove {
-                    log::info!(
-                        "Removing processed event from priority queue: {:?}",
-                        event_id
-                    );
-                    Self::remove_event_from_priority_queue(event_id)?;
-                }
-            }
-
-            Ok(())
-        }
-
-        fn remove_event_from_priority_queue(event_id: u64) -> Result<(), Error<T>> {
-            // Call the HTTP method to remove the event from the priority queue
-            let remove_event_payload = serde_json::json!({
-                "jsonrpc": "2.0",
-                "method": "remove_event",
-                "params": [event_id],
-                "id": 1
-            })
-            .to_string()
-            .into_bytes();
-            let remove_event_payload_ref: Vec<&[u8]> = vec![&remove_event_payload];
-
-            const HTTP_REMOTE_REQUEST: &str = "http://127.0.0.1:5555";
-            const HTTP_HEADER_USER_AGENT: &str = "SubstrateOffchainWorker";
-            const HTTP_HEADER_CONTENT_TYPE: &str = "Content-Type";
-            const CONTENT_TYPE_JSON: &str = "application/json";
-            const FETCH_TIMEOUT_PERIOD: u64 = 5000; // in milliseconds
-
-            let request =
-                rt_offchain::http::Request::post(HTTP_REMOTE_REQUEST, remove_event_payload_ref)
-                    .add_header("User-Agent", HTTP_HEADER_USER_AGENT)
-                    .add_header(HTTP_HEADER_CONTENT_TYPE, CONTENT_TYPE_JSON)
-                    .deadline(
-                        sp_io::offchain::timestamp()
-                            .add(rt_offchain::Duration::from_millis(FETCH_TIMEOUT_PERIOD)),
-                    )
-                    .send()
-                    .map_err(|_| <Error<T>>::HttpFetchingError)?;
-
-            let response = request
-                .try_wait(
-                    sp_io::offchain::timestamp()
-                        .add(rt_offchain::Duration::from_millis(FETCH_TIMEOUT_PERIOD)),
-                )
-                .map_err(|_| <Error<T>>::HttpFetchingError)?
-                .map_err(|_| <Error<T>>::HttpFetchingError)?;
-
-            log::info!("Response code: {}", response.code);
-
-            let body = response.body().collect::<Vec<u8>>();
-            match String::from_utf8(body.clone()) {
-                Ok(json_string) => {
-                    log::info!("Response body: {}", json_string);
-                }
-                Err(e) => {
-                    log::error!("Failed to parse response body as UTF-8: {:?}", e);
-                    log::info!("Response body bytes: {:?}", body);
-                }
-            }
-
-            Ok(())
-        }
-
-        fn get_event(event_id: u64) -> Option<CustomEvent> {
-            Some(EventStorage::<T>::get(event_id))
-        }
-    }
-
-    #[derive(Deserialize, Debug)]
-    struct Asset {
-        // Define the expected fields
-        asset_id: String,
-        quantity: u64,
-    }
-
-    impl<T: Config> Pallet<T> {
-        fn process_response(data: Vec<u8>) -> Result<(), &'static str> {
-            if let Ok(assets) = serde_json::from_slice::<Vec<Asset>>(&data) {
-                // Process each asset
-                for asset in assets {
-                    log::info!("Asset ID: {}, Quantity: {}", asset.asset_id, asset.quantity);
-                }
-            } else {
-                log::error!("Failed to parse JSON data");
-                return Err("Failed to parse JSON");
-            }
-
-            Ok(())
-        }
-    }
-
-    impl<T: Config> Pallet<T> {
-        fn process_decoded_call(call: Call<T>) -> DispatchResult {
-            match call {
-                Call::process_epoch_event { nonce, payload } => {
-                    log::info!("Processing decoded call with nonce: {}", nonce);
-
-                    Ok(())
-                }
-                _ => Err(Error::<T>::InvalidCall.into()),
-            }
-        }
-    }
-
-    #[pallet::call]
-    impl<T: Config> Pallet<T> {
-        #[pallet::call_index(0)]
-        #[pallet::weight(10_000)]
-        pub fn manual_fetch(origin: OriginFor<T>) -> DispatchResult {
-            ensure_signed(origin)?;
-
-            // Fetch and process data from the priority queue
-            match Self::fetch_and_process_events_from_queue() {
-                Ok(_) => {
-                    Self::deposit_event(Event::DataFetchedSuccessfully);
-                    Ok(())
-                }
-                Err(e) => {
-                    log::error!("Error in manual fetch: {:?}", e);
-                    Err(Error::<T>::HttpFetchingError.into())
-                }
-            }
-        }
-        #[pallet::call_index(1)]
-        #[pallet::weight(10_000)]
-        pub fn process_epoch_event(
-            origin: OriginFor<T>,
-            nonce: u64,
-            payload: Vec<u8>,
-        ) -> DispatchResult {
-            let _who = ensure_signed(origin)?;
-            log::info!("Received payload: {:?}", payload);
-
-            // Decode the payload using SCALE codec
-            let decoded_payload = CustomEvent::decode(&mut &payload[..]).map_err(|e| {
-                log::error!("Failed to decode payload: {:?}", e);
-                Error::<T>::InvalidPayload
-            })?;
-
-            log::info!("Decoded payload: {:?}", decoded_payload);
-
-            // Process the payload as needed
-            Ok(())
-        }
-        #[pallet::call_index(2)]
-        #[pallet::weight(10_000)]
-        pub fn submit_encoded_payload(origin: OriginFor<T>, payload: Vec<u8>) -> DispatchResult {
-            log::info!("submit_encoded_payload called with payload: {:?}", payload);
-
-            let _who = ensure_none(origin)?;
-
-            // Decode the payload
-            let call: Call<T> = Decode::decode(&mut &payload[..]).map_err(|e| {
-                log::error!("Failed to decode payload: {:?}", e);
-                Error::<T>::InvalidPayload
-            })?;
-
-            // Process the decoded call
-            log::info!("Processing decoded call: {:?}", call);
-            Self::process_decoded_call(call)
-        }
-    }
-
-    #[pallet::error]
-    pub enum Error<T> {
-        NoneValue,
-        StorageOverflow,
-        InvalidEventData,
-        EventNotFound,
-        HttpFetchingError,
-        InvalidPayload,
-        InvalidCall,
-        InvalidResponseFormat,
-        InvalidUtf8,
-        TransactionSubmissionError, // New error variant
-    }
-
-    #[pallet::event]
-    #[pallet::generate_deposit(pub(super) fn deposit_event)]
-    pub enum Event<T: Config> {
-        DataFetchedSuccessfully,
-    }
-
-    #[pallet::type_value]
-    pub fn DefaultForRuntimeEvent() -> () {
-        ()
-    }
-
-    pub trait WeightInfo {
-        fn some_extrinsic() -> Weight {
-            Weight::zero()
-        }
-    }
-
-    impl WeightInfo for () {
-        fn some_extrinsic() -> Weight {
-            Weight::zero()
-        }
-    }
-}
diff --git a/runtime/Cargo.toml b/runtime/Cargo.toml
index b5965f2..75a80d4 100644
--- a/runtime/Cargo.toml
+++ b/runtime/Cargo.toml
@@ -73,6 +73,9 @@ pallet-evm-precompile-sha3fips = { workspace = true }
 pallet-evm-precompile-simple = { workspace = true }
 pallet-hotfix-sufficients = { workspace = true }
 sp-application-crypto = { workspace = true }
+
+environmental = { workspace = true }
+
 [build-dependencies]
 substrate-wasm-builder = { workspace = true, optional = true }
 
diff --git a/runtime/src/lib.rs b/runtime/src/lib.rs
index 8dcfecf..187f103 100644
--- a/runtime/src/lib.rs
+++ b/runtime/src/lib.rs
@@ -5,6 +5,8 @@
 #![recursion_limit = "256"]
 #![allow(clippy::new_without_default, clippy::or_fun_call)]
 #![cfg_attr(feature = "runtime-benchmarks", warn(unused_crate_dependencies))]
+#[macro_use]
+extern crate environmental;
 
 // Make the WASM binary available.
 #[cfg(feature = "std")]
